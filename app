import io
import json
import tempfile
from typing import Dict, Any, Optional

import streamlit as st
from PIL import Image

import google.generativeai as genai
import docx
import whisper

from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline


# ==============================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==============================
st.set_page_config(
    page_title="MAGIé¢¨ãƒãƒ«ãƒAIåˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆç²¾åº¦é‡è¦–ç‰ˆï¼‰",
    page_icon="ğŸ§¬",
    layout="wide",
)

st.title("ğŸ§¬ MAGIé¢¨ ãƒãƒ«ãƒAIåˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆç²¾åº¦é‡è¦–ç‰ˆï¼‰")
st.caption("Gemini 2.5 Flash + HuggingFace LLM + Whisper ã«ã‚ˆã‚‹å¤šè¦–ç‚¹ãƒ»é«˜ç²¾åº¦åˆ†æ")


# ==============================
# å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹è¨­å®š
# ==============================
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])


@st.cache_resource(show_spinner=False)
def get_gemini_model():
    return genai.GenerativeModel("gemini-2.5-flash")


@st.cache_resource(show_spinner=True)
def load_whisper_model():
    # æ—¥æœ¬èªã‚‚æ¯”è¼ƒçš„å®‰å®šã—ã¦ã„ã‚‹ base ãƒ¢ãƒ‡ãƒ«
    return whisper.load_model("base")


@st.cache_resource(show_spinner=True)
def load_hf_pipeline(model_name: str):
    """
    Hugging Face LLM ã‚’èª­ã¿è¾¼ã‚“ã§ text-generation ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è¿”ã™ã€‚
    ç²¾åº¦é‡è¦–ã®ãŸã‚ã€æ¸©åº¦ã¯ä½ã‚ãƒ»é•·ã‚ã®å‡ºåŠ›ã‚’è¨±å®¹ã€‚
    """
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        torch_dtype="auto",
    )
    gen = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=800,
        do_sample=True,
        temperature=0.3,  # ç²¾åº¦é‡è¦–ã§ä½ã‚
        top_p=0.9,
    )
    return gen


# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼šåª’ä½“ãƒ†ã‚­ã‚¹ãƒˆåŒ–ãªã©
# ==============================
def transcribe_audio(uploaded_file) -> str:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ Whisper ã§æ–‡å­—èµ·ã“ã—"""
    model = load_whisper_model()
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name
    result = model.transcribe(tmp_path, language="ja")
    return result.get("text", "")


def describe_image_with_gemini(img: Image.Image) -> str:
    """ç”»åƒã®å†…å®¹ã‚’ Gemini ã«è¦ç´„ã•ã›ã‚‹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆåŒ–ï¼‹å°è±¡ï¼‰"""
    model = get_gemini_model()
    prompt = """
ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã‚‹ã‹ã€æ—¥æœ¬èªã§ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
ç¶šã‘ã¦ã€ãã®ç”»åƒãŒä¸ãˆã‚‹å¿ƒç†çš„ãªå°è±¡ã‚’ä¸€è¡Œã§è¿°ã¹ã¦ãã ã•ã„ã€‚
"""
    resp = model.generate_content([prompt, img])
    return resp.text.strip()


def call_gemini_structured(role_prompt: str, context: Dict[str, Any]) -> str:
    """
    å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ Gemini å‘¼ã³å‡ºã—ï¼ˆæ§‹é€ åŒ–å‡ºåŠ›ï¼‰ã€‚
    """
    model = get_gemini_model()

    sys_prompt = f"""
ã‚ãªãŸã¯ä»¥ä¸‹ã®å½¹å‰²ã‚’æŒã¤ MAGI ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€å“¡ã§ã™ã€‚

[ã‚ãªãŸã®å½¹å‰²]
{role_prompt}

[å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšã“ã®é †ç•ªãƒ»è¦‹å‡ºã—ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ï¼‰]
### ã€å‰æèªè­˜ã€‘
- ï¼ˆçŠ¶æ³ã‚„å‰æã‚’ç®‡æ¡æ›¸ãã§æ•´ç†ï¼‰

### ã€åˆ†æã€‘
- ï¼ˆã‚ãªãŸã®è¦³ç‚¹ã‹ã‚‰ã®è©³ç´°ãªåˆ†æï¼‰

### ã€ãƒªã‚¹ã‚¯ãƒ»æ‡¸å¿µã€‘
- ï¼ˆæƒ³å®šã•ã‚Œã‚‹ãƒªã‚¹ã‚¯ã‚„ä¸ç¢ºå®Ÿæ€§ï¼‰

### ã€ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµè«–ã¨ææ¡ˆã€‘
- çµè«–ï¼š
- ææ¡ˆï¼š
"""

    user_context = json.dumps(context, ensure_ascii=False, indent=2)

    resp = model.generate_content(
        [
            sys_prompt,
            f"ä»¥ä¸‹ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æƒ…å ±ã§ã™ã€‚ã“ã‚Œã«åŸºã¥ã„ã¦é«˜ç²¾åº¦ã«åˆ†æã—ã¦ãã ã•ã„ã€‚\n\n{user_context}",
        ]
    )
    return resp.text.strip()


def call_hf_llm_structured(model_name: str, role_prompt: str, context: Dict[str, Any]) -> str:
    """
    Hugging Face LLM ã‚’ä½¿ã£ãŸæ§‹é€ åŒ–å‡ºåŠ›ã€‚
    """
    gen = load_hf_pipeline(model_name)
    user_context = json.dumps(context, ensure_ascii=False, indent=2)

    sys_and_format = f"""
ã‚ãªãŸã¯ä»¥ä¸‹ã®å½¹å‰²ã‚’æŒã¤ MAGI ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€å“¡ã§ã™ã€‚

[ã‚ãªãŸã®å½¹å‰²]
{role_prompt}

[å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšã“ã®è¦‹å‡ºã—ãƒ»é †ç•ªãƒ»æ§‹é€ ã‚’å®ˆã‚‹ã“ã¨ï¼‰]
### ã€å‰æèªè­˜ã€‘
- ç®‡æ¡æ›¸ãã§

### ã€åˆ†æã€‘
- ç®‡æ¡æ›¸ãã‚„çŸ­ã„æ®µè½ã§è©³ã—ã

### ã€ãƒªã‚¹ã‚¯ãƒ»æ‡¸å¿µã€‘
- ç®‡æ¡æ›¸ãã§

### ã€ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµè«–ã¨ææ¡ˆã€‘
- çµè«–ï¼š
- ææ¡ˆï¼š
"""

    prompt = (
        sys_and_format
        + "\n\nä»¥ä¸‹ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æƒ…å ±ã§ã™ã€‚ã“ã‚Œã«åŸºã¥ã„ã¦æ—¥æœ¬èªã§æ…é‡ã«åˆ†æã—ã¦ãã ã•ã„ã€‚\n"
        + user_context
        + "\n\nä¸Šè¨˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )

    out = gen(prompt)[0]["generated_text"]
    # ã–ã£ãã‚Šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†ã‚’å‰Šé™¤
    trimmed = out[len(prompt):].strip()
    return trimmed if trimmed else out.strip()


def call_gemini_aggregator(agent_outputs: Dict[str, str], context: Dict[str, Any]) -> str:
    """
    å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›ã‚’çµ±åˆã™ã‚‹æœ€çµ‚ MAGIã€‚
    """
    model = get_gemini_model()

    sys_prompt = """
ã‚ãªãŸã¯ NERV ã® MAGI ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹çµ±åˆ AI ã§ã™ã€‚

[å½¹å‰²]
- å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ†æçµæœã‚’èª­ã¿å–ã‚Šã€çŸ›ç›¾ç‚¹ãƒ»å…±é€šç‚¹ãƒ»è£œå®Œé–¢ä¿‚ã‚’æ•´ç†ã™ã‚‹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦å®Ÿè¡Œå¯èƒ½ã§ç¾å®Ÿçš„ãªã€Œçµè«–ã€ã¨ã€Œå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã€ã‚’æç¤ºã™ã‚‹
- å¿…è¦ã«å¿œã˜ã¦ã€Goï¼ˆå®Ÿè¡Œã™ã¹ãï¼‰ / Holdï¼ˆæ¡ä»¶ä»˜ãã§æ¤œè¨ï¼‰ / No-Goï¼ˆè¦‹é€ã‚‹ã¹ãï¼‰ã®åˆ¤æ–­ã‚‚è¡Œã†

[å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ]
### ã€å…¨ä½“ã‚µãƒãƒªãƒ¼ã€‘
- 3ã€œ7è¡Œç¨‹åº¦ã§è¦ç´„

### ã€åˆè­°çµæœã®è¦ç‚¹ã€‘
- Magi-Logicï¼š
- Magi-Humanï¼š
- Magi-Realityï¼š
- Magi-Mediaï¼š

### ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã€‘
- ï¼ˆã‚¹ãƒ†ãƒƒãƒ—å½¢å¼ã§åˆ—æŒ™ï¼‰

### ã€MAGIã¨ã—ã¦ã®æœ€çµ‚åˆ¤æ–­ã€‘
- åˆ¤æ–­ï¼šGo / Hold / No-Go ã®ã„ãšã‚Œã‹
- ç†ç”±ï¼š
"""

    context_text = json.dumps(context, ensure_ascii=False, indent=2)
    agents_text = json.dumps(agent_outputs, ensure_ascii=False, indent=2)

    resp = model.generate_content(
        [
            sys_prompt,
            f"[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒæƒ…å ±]\n{context_text}\n\n[å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœ]\n{agents_text}",
        ]
    )
    return resp.text.strip()


def build_word_report(
    context: Dict[str, Any],
    agent_outputs: Dict[str, str],
    aggregated: str,
    image: Optional[Image.Image] = None,
) -> bytes:
    """MAGIé¢¨ç« ç«‹ã¦ã® Word ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
    doc = docx.Document()
    doc.add_heading("MAGIé¢¨ãƒãƒ«ãƒAIåˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆç²¾åº¦é‡è¦–ï¼‰", level=1)

    # 1. å…¥åŠ›æƒ…å ±
    doc.add_heading("ç¬¬1ç«  å…¥åŠ›æƒ…å ±", level=2)
    doc.add_paragraph(f"â–  ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ï¼š{context.get('user_question', '')}")
    if context.get("text_input"):
        doc.add_paragraph("â–  ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ï¼š")
        doc.add_paragraph(context["text_input"])
    if context.get("audio_transcript"):
        doc.add_paragraph("â–  éŸ³å£°æ–‡å­—èµ·ã“ã—ï¼š")
        doc.add_paragraph(context["audio_transcript"])
    if context.get("image_description"):
        doc.add_paragraph("â–  ç”»åƒã®èª¬æ˜ï¼š")
        doc.add_paragraph(context["image_description"])

    if image is not None:
        img_stream = io.BytesIO()
        image.save(img_stream, format="PNG")
        img_stream.seek(0)
        doc.add_picture(img_stream, width=docx.shared.Inches(3))

    # 2. å„MAGIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ†æ
    doc.add_heading("ç¬¬2ç«  å„MAGIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ†æ", level=2)
    for name, text in agent_outputs.items():
        doc.add_heading(name, level=3)
        for line in text.splitlines():
            doc.add_paragraph(line)

    # 3. MAGIçµ±åˆAIã®çµè«–
    doc.add_heading("ç¬¬3ç«  MAGIçµ±åˆAIã®çµè«–ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³", level=2)
    for line in aggregated.splitlines():
        doc.add_paragraph(line)

    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.getvalue()


# ==============================
# UIï¼šå…¥åŠ›ã‚¨ãƒªã‚¢
# ==============================
st.markdown("### 1. è³ªå•ãƒ»ãƒ†ãƒ¼ãƒã®å…¥åŠ›")

user_question = st.text_area(
    "ã‚ãªãŸãŒç›¸è«‡ã—ãŸã„å†…å®¹ãƒ»èããŸã„ã“ã¨ï¼ˆå¿…é ˆï¼‰",
    placeholder="ä¾‹ï¼šã“ã®ä¼ç”»æ›¸ã®æ–¹å‘æ€§ã¨æ”¹å–„ç‚¹ã‚’å¤šè§’çš„ã«æ•™ãˆã¦ã»ã—ã„\nä¾‹ï¼šã“ã®ä»•äº‹ã®é€²ã‚æ–¹ã¨ãƒªã‚¹ã‚¯ã‚’MAGIã«è©•ä¾¡ã—ã¦ã»ã—ã„ ãªã©",
    height=120,
)

st.markdown("### 2. åˆ†æã—ãŸã„åª’ä½“ï¼ˆä»»æ„ï¼‰")
col1, col2 = st.columns(2)

uploaded_file = None
uploaded_image = None
media_type = None

with col1:
    file = st.file_uploader(
        "ç”»åƒ / éŸ³å£° / ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« ãªã©",
        type=["jpg", "jpeg", "png", "wav", "mp3", "m4a", "txt"],
    )
    if file:
        uploaded_file = file

with col2:
    cam = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±ï¼ˆä»»æ„ï¼‰")
    if cam:
        uploaded_file = cam

text_input = st.text_area(
    "è£œè¶³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰",
    height=100,
    placeholder="è¿½è¨˜ã—ãŸã„èª¬æ˜ã‚„ãƒ¡ãƒ¢ãªã©ãŒã‚ã‚Œã°å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
)

if not user_question and not uploaded_file and not text_input:
    st.info("è³ªå•ã‹ã€åª’ä½“ï¼ˆç”»åƒãƒ»éŸ³å£°ãªã©ï¼‰ã€ã¾ãŸã¯è£œè¶³ãƒ†ã‚­ã‚¹ãƒˆã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ==============================
# åª’ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆåŒ–
# ==============================
context: Dict[str, Any] = {
    "user_question": user_question,
    "text_input": text_input,
    "audio_transcript": "",
    "image_description": "",
}

image_for_report: Optional[Image.Image] = None

if uploaded_file is not None:
    if uploaded_file.type.startswith("image/"):
        media_type = "image"
        image = Image.open(uploaded_file).convert("RGB")
        image_for_report = image
        st.image(image, caption="å…¥åŠ›ç”»åƒ", use_column_width=True)

        with st.spinner("ç”»åƒå†…å®¹ã‚’è§£æä¸­ï¼ˆGeminiï¼‰..."):
            img_desc = describe_image_with_gemini(image)
        context["image_description"] = img_desc

    elif uploaded_file.type.startswith("audio/"):
        media_type = "audio"
        st.audio(uploaded_file)
        with st.spinner("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­ï¼ˆWhisperï¼‰..."):
            transcript = transcribe_audio(uploaded_file)
        context["audio_transcript"] = transcript

    else:
        media_type = "other"
        if uploaded_file.type == "text/plain":
            text_bytes = uploaded_file.read()
            context["text_input"] += "\n\n[ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹]\n" + text_bytes.decode(
                "utf-8", errors="ignore"
            )

# ==============================
# MAGI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—
# ==============================
st.markdown("### 3. MAGI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹åˆ†æ")

if st.button("ğŸ” MAGI ã«ã‚ˆã‚‹åˆ†æã‚’å®Ÿè¡Œ", type="primary"):
    if not user_question and not text_input and not any(
        [context["audio_transcript"], context["image_description"]]
    ):
        st.warning("æœ€ä½ã§ã‚‚è³ªå•ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»åª’ä½“ã®ã„ãšã‚Œã‹ãŒå¿…è¦ã§ã™ã€‚")
        st.stop()

    agent_outputs: Dict[str, str] = {}

    # --- Magi-Logicï¼ˆGeminiï¼‰ ---
    with st.spinner("Magi-Logicï¼ˆè«–ç†ãƒ»æ§‹é€ æ‹…å½“ / Geminiï¼‰ãŒåˆ†æä¸­..."):
        out_logic = call_gemini_structured(
            role_prompt="""
è«–ç†ãƒ»æ§‹é€ ãƒ»å› æœé–¢ä¿‚ã®åˆ†æã«ç‰¹åŒ–ã—ãŸ AIã€‚
- å•é¡Œã®æ§‹é€ åŒ–
- è«–ç†çš„ãªçŸ›ç›¾ã®æŒ‡æ‘˜
- å®Ÿç¾ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—è¨­è¨ˆ
ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã€é«˜ç²¾åº¦ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
""",
            context=context,
        )
    agent_outputs["Magi-Logicï¼ˆè«–ç†ãƒ»æ§‹é€ æ‹…å½“ / Geminiï¼‰"] = out_logic

    # --- Magi-Humanï¼ˆHF ç²¾åº¦é‡è¦– LLMï¼‰ ---
    with st.spinner("Magi-Humanï¼ˆæ„Ÿæƒ…ãƒ»å¿ƒç†æ‹…å½“ / HF LLMï¼‰ãŒåˆ†æä¸­..."):
        hf_model_human = st.secrets.get(
            "HF_MODEL_HUMAN",
            "Qwen/Qwen2.5-7B-Instruct",
        )
        out_human = call_hf_llm_structured(
            model_name=hf_model_human,
            role_prompt="""
äººé–“ã®æ„Ÿæƒ…ãƒ»å¿ƒç†ãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ç‰¹åŒ–ã—ãŸ AIã€‚
- é–¢ä¿‚è€…ãŒã©ã‚“ãªæ°—æŒã¡ã«ãªã‚‹ã‹
- ä¼ãˆæ–¹ãƒ»è¨€è‘‰é¸ã³ã®é…æ…®
- ãƒ¡ãƒ³ã‚¿ãƒ«é¢ã®ãƒªã‚¹ã‚¯ãƒ»ã‚±ã‚¢
ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã€é«˜ç²¾åº¦ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
""",
            context=context,
        )
    agent_outputs["Magi-Humanï¼ˆæ„Ÿæƒ…ãƒ»å¿ƒç†æ‹…å½“ / HF LLMï¼‰"] = out_human

    # --- Magi-Realityï¼ˆåˆ¥HF LLMï¼‰ ---
    with st.spinner("Magi-Realityï¼ˆç¾å®Ÿãƒ»é‹ç”¨æ‹…å½“ / HF LLMï¼‰ãŒåˆ†æä¸­..."):
        hf_model_reality = st.secrets.get(
            "HF_MODEL_REALITY",
            "google/gemma-2-9b-it",
        )
        out_reality = call_hf_llm_structured(
            model_name=hf_model_reality,
            role_prompt="""
ç¾å®Ÿçš„ãªé‹ç”¨ãƒ»ã‚³ã‚¹ãƒˆãƒ»ãƒªã‚¹ã‚¯ç®¡ç†ã«ç‰¹åŒ–ã—ãŸ AIã€‚
- å®Ÿç¾å¯èƒ½æ€§
- å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã¨åˆ¶ç´„
- ç¾å ´ã§èµ·ã“ã‚Šãã†ãªå•é¡Œ
ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã€é«˜ç²¾åº¦ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
""",
            context=context,
        )
    agent_outputs["Magi-Realityï¼ˆç¾å®Ÿãƒ»é‹ç”¨æ‹…å½“ / HF LLMï¼‰"] = out_reality

    # --- Magi-Mediaï¼ˆGemini Vision/é€šå¸¸ï¼‰ ---
    with st.spinner("Magi-Mediaï¼ˆåª’ä½“è§£é‡ˆæ‹…å½“ / Geminiï¼‰ãŒåˆ†æä¸­..."):
        out_media = call_gemini_structured(
            role_prompt="""
ç”»åƒãƒ»éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãªã©åª’ä½“ã®ç‰¹å¾´ã‚’è¸ã¾ãˆãŸè§£é‡ˆã«ç‰¹åŒ–ã—ãŸ AIã€‚
- å…¥åŠ›ã•ã‚ŒãŸåª’ä½“ãŒä¸ãˆã‚‹å°è±¡
- ãã®åª’ä½“ã‚’ã©ã†æ´»ã‹ã™ã¹ãã‹
- æ”¹å–„æ¡ˆï¼ˆæ§‹å›³ãƒ»è¡¨ç¾ãƒ»é•·ã•ãªã©ï¼‰
ã«é‡ç‚¹ã‚’ç½®ã„ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚
ç”»åƒã‚„éŸ³å£°ãŒç„¡ã„å ´åˆã¯ã€æ–‡ç« è¡¨ç¾ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ã€‚
""",
            context=context,
        )
    agent_outputs["Magi-Mediaï¼ˆåª’ä½“è§£é‡ˆæ‹…å½“ / Geminiï¼‰"] = out_media

    st.success("å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœè¡¨ç¤º
    for name, text in agent_outputs.items():
        with st.expander(f"ğŸ§¬ {name}", expanded=False):
            st.markdown(text)

    # çµ±åˆãƒ•ã‚§ãƒ¼ã‚º
    st.markdown("### 4. MAGIçµ±åˆAIã®çµè«–ï¼ˆåˆè­°çµæœãƒ¬ãƒãƒ¼ãƒˆï¼‰")
    with st.spinner("MAGIçµ±åˆAIãŒçµè«–ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™..."):
        aggregated = call_gemini_aggregator(agent_outputs, context)
    st.markdown(aggregated)

    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    report_bytes = build_word_report(
        context=context,
        agent_outputs=agent_outputs,
        aggregated=aggregated,
        image=image_for_report,
    )

    st.markdown("### 5. ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")
    st.download_button(
        "ğŸ“ MAGIãƒ¬ãƒãƒ¼ãƒˆï¼ˆWordï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=report_bytes,
        file_name="MAGIåˆ†æãƒ¬ãƒãƒ¼ãƒˆ_ç²¾åº¦é‡è¦–ç‰ˆ.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    )

else:
    st.info("ã€ŒğŸ” MAGI ã«ã‚ˆã‚‹åˆ†æã‚’å®Ÿè¡Œã€ã‚’æŠ¼ã™ã¨ã€å„AIãŒé †ç•ªã«åˆ†æã‚’é–‹å§‹ã—ã¾ã™ã€‚")
